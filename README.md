# GhostHire Detector

GhostHire Detector is a backend-driven system for analyzing job postings and identifying potential fraud patterns using a deterministic, rule-based engine. It exposes a RESTful Flask API and a lightweight React client for interaction and visualization.

The system prioritizes:
- Explainability over black-box scoring
- Fault isolation across rules
- Clear separation of ingestion, analysis, and presentation
- Automated testability

---

## System Architecture

```
Client (React)
  â†“
API Layer (Flask)
  â†“
Ingestion Layer (optional: URL â†’ HTML â†’ Text)
  â†“
Parsing Layer (raw JD â†’ JDContext)
  â†“
Analysis Engine
  â”œâ”€â”€ Fraud Rules (JDContext-only)
  â””â”€â”€ Insights
```

The backend is the source of truth.  
The frontend is a stateless consumer of API responses.

The backend processes ALL job descriptions into a structured JDContext before analysis. No rule runs on raw text anymore.

---

## Functional Overview

### Fraud Analysis
- Rule-based scoring system (0.0 â€“ 1.0)
- Independent, failure-tolerant rules
- Deterministic and explainable outputs

Implemented fraud signals (via JDContext structured analysis):
- Urgent / pressure-driven hiring signals
- Urgency density anomalies
- Unrealistic salary or salaryâ€“experience mismatch
- Roleâ€“salary inconsistency
- Missing or vague company identity
- Generic / suspicious contact channels
- Over-promising language & guaranteed placement claims
- Suspicious / shortcut hiring process
- Generic or scam-pattern job titles
- Linguistic inconsistency & tone anomalies
- Reused / duplicated / template job descriptions

---

### Insights (Non-Scoring)
Structured insights are extracted independently of fraud scoring. Currently implemented:
- Skill / technology extraction
Returned as structured metadata and does not influence fraud risk score.

---

### Supported Inputs
- Raw job description text (pasted by user)
- Public job posting URL (server ingestion â†’ scrape â†’ extract â†’ normalize â†’ parse)

---

## Ingestion Layer (Enhanced)

The ingestion pipeline has been upgraded to behave closer to real-world production systems.

**Responsibilities**
- Fetch trusted HTML from public job URLs
- Apply realistic headers & redirects
- Validate content-type & encoding
- Extract readable job content
- Normalize and clean text
- Fail gracefully without crashing the pipeline

**Pipeline**
```
URL â†’ fetch_url_content()  
       â†“  
HTML â†’ extract_job_description()  
       â†“  
Text â†’ normalize_job_description()  
       â†“  
debug/raw_jd.txt (captured for inspection)
```

Scraping never lives in frontend.  
Failures return clear API errors instead of breaking analysis.

---

## Parsing Layer (Structured JDContext)

All analysis is now **fully structured**.  
No fraud rule consumes raw text anymore â€” everything runs on parsed semantics.

**The parser now extracts:**
- ğŸ“ Location + Remote / Hybrid / Onâ€‘site
- ğŸ§  Experience years (min / max where available)
- ğŸ’¼ Employment type (Fullâ€‘time / Contract / Internship)
- ğŸ Hiring process structure (steps, interviews, shortcuts)
- ğŸ’¸ Salary structure (amount, range, currency, frequency)
- ğŸ¢ Company inference heuristics
- ğŸ“§ Verifiable emails
- Confidence scores per attribute
- Overall parsing confidence baseline

**Architecture**
```
Raw JD Text
 â†“
Parsing Detectors
 â†“
JDContext (structured representation)
 â†“
Fraud Rules + Insights
```

This significantly improves:
- Accuracy
- Explainability
- Realâ€‘world reliability
- Extensibility (future ML & domainâ€‘specific extractors)

---

## Backend Layout

```
backend/
â”œâ”€â”€ app.py                     # API entry point
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ analysis_engine.py     # Orchestrates rules + insights (JDContext only)
â”‚   â”œâ”€â”€ rules/                 # Individual fraud rules (fault-tolerant)
â”‚   â”œâ”€â”€ insights/              # Non-fraud analysis
â”‚   â”œâ”€â”€ ingestion/             # URL â†’ HTML â†’ JD text
â”‚   â”‚   â”œâ”€â”€ url_fetcher.py
â”‚   â”‚   â”œâ”€â”€ jd_extractor.py
â”‚   â”‚   â””â”€â”€ normalizer.py
â”‚   â””â”€â”€ parsing/
â”‚       â”œâ”€â”€ jd_parser.py           # Converts text â†’ JDContext
â”‚       â”œâ”€â”€ schema.py              # JDContext + structured models
â”‚       â”œâ”€â”€ detectors/             # Individual semantic extractors
â”‚       â”‚   â”œâ”€â”€ experience_detector.py
â”‚       â”‚   â”œâ”€â”€ location_detector.py
â”‚       â”‚   â”œâ”€â”€ employment_type_detector.py
â”‚       â”‚   â”œâ”€â”€ hiring_flow_detector.py
â”‚       â”‚   â””â”€â”€ salary_detector.py
â”‚       â””â”€â”€ utils.py                 # shared parsing helpers
â”œâ”€â”€ debug/
â”‚   â””â”€â”€ raw_jd.txt             # Temporary captured JD for inspection
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ loc_counter.py         # LOC calculation (backend + frontend)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ rules/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ insights/
â”‚   â””â”€â”€ test_analysis_engine.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ pytest.ini
```

---

## Frontend Layout

```
frontend/ghosthire-ui/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ LandingOptions.js
â”‚   â”‚   â”œâ”€â”€ JDTextInput.js
â”‚   â”‚   â””â”€â”€ JDUrlInput.js
â”‚   â”œâ”€â”€ App.js
â”‚   â”œâ”€â”€ App.css
â”‚   â””â”€â”€ index.js
â””â”€â”€ package.json
```

---

## API Specification

### POST `/analyze`

#### Request (text input)
```json
{
  "job_text": "Job description content"
}
```

#### Request (URL input)
```json
{
  "job_url": "https://example.com/job-posting"
}
```

#### Response
```json
{
  "rule_score": 0.8,
  "reasons": [
    "Urgent call-to-action language detected",
    "Generic email contact used instead of company domain"
  ],
  "insights": {
    "skills": {
      "skills_found": ["python", "react"],
      "skill_count": 2
    }
  }
}
```

Note:
All analysis now runs on JDContext (structured representation). Even pasted text is normalized and parsed before scoring.

---

## Local Development

### Backend
```bash
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python app.py
```

Runs on:
```
http://127.0.0.1:5000
```

---

### Frontend
```bash
cd frontend/ghosthire-ui
npm install
npm start
```

Runs on:
```
http://localhost:3000
```

---

## Testing

Backend functionality is validated using pytest with coverage support, including ingestion, parsing, and analysis engine layers.

```bash
cd backend
pytest
```

With coverage:
```bash
pytest --cov=analyzer --cov-report=term-missing
```

---

## Design Constraints

- No scraping logic in frontend
- Rules do not depend on each other
- Analysis engine operates ONLY on JDContext (not raw strings)
- Ingestion failures never crash analysis
- Rule failures never crash the engine
- Frontend remains a stateless consumer

---

## Roadmap

- Advanced parsing heuristics & ML-assisted extraction
- Domain-specific JD extractors (LinkedIn, Indeed, Naukri, etc.)
- Context-aware semantic fraud rules
- Embedding-based copy/paste similarity detection
- PDF & document ingestion pipeline
- Confidence calibration across rules

---

## Owner

Raghav Patodiya